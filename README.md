# An√°lisis de Brechas Educacionales en Chile 2024

## üìä An√°lisis de Datos Educacionales a Gran Escala con Python

Este proyecto demuestra t√©cnicas para el **procesamiento eficiente de archivos CSV masivos** (3.6M+ registros) utilizando Python y pandas, enfoc√°ndose en el an√°lisis de brechas educacionales en el sistema escolar chileno.

## üöÄ Caracter√≠sticas T√©cnicas Principales

### **Procesamiento de Archivos Grandes**
- ‚úÖ **Chunking Strategy**: Procesamiento por lotes de 100,000 registros
- ‚úÖ **Memory Management**: Gesti√≥n eficiente de memoria para datasets de GB
- ‚úÖ **Encoding Handling**: Manejo autom√°tico de UTF-8 y caracteres especiales

### **Pipeline de Datos**
1. **Exploraci√≥n inicial** (`00_exploracion.py`)
2. **Transformaci√≥n y limpieza** (`01_transformaciones_y_limpieza.py`)
3. **An√°lisis estad√≠stico** (`02_analisis.py`)

## üõ†Ô∏è Ventajas del Enfoque con Python

### **¬øPor qu√© Python para Archivos Grandes?**

#### **1. Procesamiento por Chunks**
```python
# T√©cnica clave: No cargar todo en memoria
chunk_iterator = pd.read_csv(
    archivo, 
    chunksize=100000,  # Procesar de 100k en 100k
    low_memory=False
)

for chunk in chunk_iterator:
    # Procesar cada bloque independientemente
    chunk_procesado = procesar_chunk(chunk)
    chunks_limpios.append(chunk_procesado)
```

#### **2. Manejo Inteligente de Encoding**
```python
# Soluci√≥n a problemas de caracteres especiales
sys.stdout.reconfigure(encoding='utf-8')
chunk['COLUMNA'] = chunk['COLUMNA'].astype(str).str.replace(',', '.')
```

#### **3. Filtrado Eficiente**
```python
# Filtros aplicados antes de cargar en memoria
chunk_filtrado = chunk[
    (chunk['ESTADO_ESTAB'] == 1) &  # Solo establecimientos activos
    (chunk['SIT_FIN_R'].isin(['P', 'R']))  # Solo promovidos/reprobados
].copy()
```

## üìà Resultados del An√°lisis

### **Datos Procesados**
- **Total registros**: 3,568,930 ‚Üí 3,076,190 v√°lidos
- **Tiempo de procesamiento**: ~23 segundos
- **Memoria utilizada**: <2GB (vs 15GB+ sin chunking)

### **Brechas Identificadas**

#### **Por Tipo de Establecimiento**
| Tipo | Promedio | Estudiantes |
|------|----------|-------------|
| Particular Pagado | 6.37 | 300,629 |
| Particular Subvencionado | 6.00 | 1,606,172 |
| Municipal | 5.97 | 926,323 |
| Corp. Adm. Delegada | 5.64 | 42,969 |

#### **Por G√©nero**
- **Femenino**: 6.10 (1,498,340 estudiantes)
- **Masculino**: 5.94 (1,577,842 estudiantes)
- **Brecha**: 0.16 puntos (2.7% diferencia)

#### **Por Zona Geogr√°fica**
- **Rural**: 6.11 promedio
- **Urbano**: 6.01 promedio

## üîß Stack Tecnol√≥gico

### **Librer√≠as Core**
```python
import pandas as pd        # Manipulaci√≥n de datos
import numpy as np         # Operaciones num√©ricas
import matplotlib.pyplot as plt  # Visualizaci√≥n
import seaborn as sns      # Gr√°ficos estad√≠sticos
```

## üìä Visualizaciones Generadas

El proyecto genera autom√°ticamente:
- Histogramas de distribuci√≥n
- Gr√°ficos de barras comparativos
- Box plots para an√°lisis de dispersi√≥n
- Visualizaciones multi-panel

## ‚ö° Ventajas del Enfoque vs Alternativas

### **Python + Pandas vs Excel**
| Aspecto | Python | Excel |
|---------|--------|-------|
| **Tama√±o m√°ximo** | Ilimitado | 1M filas |
| **Velocidad** | ~23s para 3.6M | Crash |
| **Automatizaci√≥n** | 100% | Limitada |
| **Memoria** | Eficiente | Ineficiente |


## üöÄ C√≥mo Ejecutar

### **Prerequisitos**
```bash
pip install pandas numpy matplotlib seaborn
```

### **Ejecuci√≥n**
```bash
# 1. Exploraci√≥n inicial
python scripts/00_exploracion.py

# 2. Limpieza y transformaci√≥n
python scripts/01_transformaciones_y_limpieza.py

# 3. An√°lisis de brechas
python scripts/02_analisis.py
```

## üìÅ Estructura del Proyecto

```
analisis-educacional-chile/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ rendimiento_2024.csv           # Dataset original (3.6M registros)
‚îÇ   ‚îî‚îÄ‚îÄ rendimiento_limpio_2024.csv    # Dataset procesado
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ 00_exploracion.py              # EDA inicial
‚îÇ   ‚îú‚îÄ‚îÄ 01_transformaciones_y_limpieza.py  # Pipeline de limpieza
‚îÇ   ‚îî‚îÄ‚îÄ 02_analisis.py                 # An√°lisis estad√≠stico
‚îú‚îÄ‚îÄ output/
‚îÇ   ‚îú‚îÄ‚îÄ *.png                          # Visualizaciones
‚îÇ   ‚îî‚îÄ‚îÄ *.txt                          # Logs de ejecuci√≥n
‚îî‚îÄ‚îÄ env/                               # Entorno virtual
```

## üéØ Lecciones T√©cnicas Aprendidas

### **1. Problema de Encoding**
**S√≠ntoma**: Caracteres especiales aparec√≠an como s√≠mbolos extra√±os
**Soluci√≥n**: `sys.stdout.reconfigure(encoding='utf-8')`

### **2. Problema de Decimales**
**S√≠ntoma**: 90% de datos se convert√≠an a NaN
**Soluci√≥n**: Conversi√≥n de comas a puntos antes de `pd.to_numeric()`

### **3. Problema de Memoria**
**S√≠ntoma**: Sistema se quedaba sin memoria
**Soluci√≥n**: Procesamiento por chunks de 100k registros

### **4. Problema de Performance**
**S√≠ntoma**: Procesamiento lento
**Soluci√≥n**: Filtros aplicados antes de operaciones costosas

## üîç Casos de Uso

Este enfoque es ideal para:
- **An√°lisis gubernamentales** con millones de registros
- **Data Science** en datasets grandes
- **Business Intelligence** automatizada
- **Reportes** recurrentes con big data
- **Investigaci√≥n acad√©mica** con datos masivos

## üìö Conclusiones T√©cnicas

Python demuestra ser **superior** para an√°lisis de archivos grandes debido a:

1. **Escalabilidad**: Maneja datasets de cualquier tama√±o
2. **Flexibilidad**: Adaptable a cualquier formato de datos
3. **Automatizaci√≥n**: Scripts reutilizables y programables
4. **Performance**: Optimizado para operaciones vectorizadas
5. **Ecosystem**: Librer√≠as especializadas para cada necesidad

---

**Dataset**: Datos del Ministerio de Educaci√≥n de Chile 2024 
            https://datosabiertos.mineduc.cl/rendimiento-por-estudiante-2/  
**Objetivo**: Demostrar capacidades de Python para an√°lisis
